{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b9b4e7",
   "metadata": {},
   "source": [
    "# Scraping data from Retrosheet.org: Part 3 - parsing the seasonal split page\n",
    "\n",
    "This is pretty much the same as part 2, which parses the career page.\n",
    "\n",
    "The only one improvement I will try is to react better on the 404 error page.\n",
    "- In part 2, it will raise an error and will have to handle everything manually and move on.\n",
    "- In part 3, I will just try to leave a line on the log file and pretend nothing is happening, if it is merely a 404.\n",
    "\n",
    "It is a huge scrape, consisting of 84k+ pages. Let's keep our hands crossed and hope things will go well. Also, I have only about 28 hours left. It is a race with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup;\n",
    "import requests;\n",
    "import re;\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from IPython.display import clear_output;\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; \\\n",
    "    Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'};\n",
    "retro_page_affix = \"https://www.retrosheet.org/boxesetc/\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc25f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process if have chance. Have a larger chance to be blocked by Retrosheet.\n",
    "df_player_yearly_stats = pd.read_csv(\"player_season_split_url.csv\", usecols = [\"ID\", \"Name\", \"Season\", \"Team\", \"split_url\"]);\n",
    "df_player_yearly_stats # 84231 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns of the dataframe\n",
    "columns_career = [\"ID\", \"Name\", \"Season\", \"Team\", \"Situation\", \"G\", \"AB\", \"R\", \"H\", \"2B\", \"3B\", \"HR\", \"RBI\",\\\n",
    "                  \"BB\", \"IBB\", \"SO\", \"HBP\", \"SH\", \"SF\", \"XI\", \"ROE\", \"GDP\", \"SB\", \"CS\", \"AVG\", \"OBP\", \"SLG\"]; # len() = 27\n",
    "situations = [\"Total\", \"Home\", \"Away\", \"vs RHP\", \"vs LHP\", \"Day\", \"Night\", \"None On\", \"Men On\", \"RISP\", \"Close & Late\", \\\n",
    "              \"Bases Loaded\", \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \\\n",
    "              \"October\", \"November\", \"December\", \"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \\\n",
    "              \"AT P \", \"AT C \", \"AT 1B\", \"AT 2B\", \"AT 3B\", \"AT SS\", \"AT LF\", \"AT CF\", \"AT RF\", \"AT OF\", \"AT DH\", \"AT PH\", \\\n",
    "              \"AT PR\", \"AT H\", \"AT >1\"]; # len() = 48\n",
    "situations_len = [len(x) for x in situations];\n",
    "(situations_len[33], situations_len[34]) = (4,4);\n",
    "situations_no_g = [3,4,7,8,9,10,11]; # situation tags with no G provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208fc6b",
   "metadata": {},
   "source": [
    "### Now, we write a function to scrape the link in the i-th row, but the rules of the game is really the same as part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295363f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_season_split(entry):\n",
    "    ''' Scrape a player in the dataframe, specified by entry.\n",
    "    If scraped successfully, return a nested list which can be fed to the data frame.\n",
    "    If a 404 error occurs, return the number -1\n",
    "    \n",
    "    Arguments: entry: the index of the dataframe. Not the id!\n",
    "    '''\n",
    "    ID = df_player_yearly_stats.loc[entry,\"ID\"];\n",
    "    name = df_player_yearly_stats.loc[entry,\"Name\"];\n",
    "    season = df_player_yearly_stats.loc[entry, \"Season\"];\n",
    "    team = df_player_yearly_stats.loc[entry, \"Team\"];\n",
    "    url = df_player_yearly_stats.loc[entry,\"split_url\"];\n",
    "\n",
    "    response = requests.get(url, headers=headers);\n",
    "    text = BeautifulSoup(response.text, 'html.parser');\n",
    "\n",
    "    if response.status_code == 404:\n",
    "        print(\"404 on \" + name + \" in \" + str(season) + \" at\" + team);\n",
    "        with open(\"Seasonal_split_descrepency.log\", 'a') as f:\n",
    "            file_buffer = str(ID) + \", \" + name + \", \" + str(season) + \", \" + team + \", \" + url + \", season split missing\\n\";\n",
    "            f.write(file_buffer);\n",
    "        return -1;\n",
    "    elif response.status_code != 200:\n",
    "        raise Exception(f\"The status code is not 200! It is {response.status_code}.\");\n",
    "\n",
    "    pret = text.findAll(\"pre\");\n",
    "\n",
    "    for ta in pret:\n",
    "        if ta.get_text().find(\"Total\") != -1:\n",
    "            clear_output();\n",
    "            print(\"Found batting record chunk for \" + name + \" in \" + str(season) + \" at \" + team + '.');\n",
    "            break;\n",
    "\n",
    "    ltemp = ta.contents[0].splitlines();\n",
    "    \n",
    "    status = ltemp[0]; # The glossary line. Use this to detect what was missing.\n",
    "    glossary = status.split();\n",
    "    glossary_complete = (len(glossary) == 22);\n",
    "    if not glossary_complete:\n",
    "        glossary_index = [columns_career.index(x)-5 for x in glossary];\n",
    "        # A mask, or indicator on where the glossary maps to in full list.\n",
    "    \n",
    "    player_career_split = [];\n",
    "    for status in ltemp:\n",
    "        # status_split = status.split();\n",
    "\n",
    "        # Try to find true\n",
    "        status_tag = [status.startswith(x) for x in situations];\n",
    "        try:\n",
    "            tag_num = status_tag.index(True);\n",
    "        except:\n",
    "            tag_num = -1;\n",
    "\n",
    "        if glossary_complete:\n",
    "            if tag_num in situations_no_g: # On tags where no G column is available, need to pad with a np.nan\n",
    "                player_career_split.append([ID, name, season, team, situations[tag_num], np.nan] + \\\n",
    "                                          status[situations_len[tag_num]:].replace('i', ' ').split());\n",
    "            elif tag_num >= 0:\n",
    "                player_career_split.append([ID, name, season, team, situations[tag_num]] + \\\n",
    "                                          status[situations_len[tag_num]:].replace('i', ' ').split());\n",
    "        else:\n",
    "            if tag_num in situations_no_g:\n",
    "                content = [np.nan] + status[situations_len[tag_num]:].replace('i', ' ').split();\n",
    "                content_dest = [np.nan] * (len(columns_career) - 5);\n",
    "                for j in range(len(glossary)):\n",
    "                    content_dest[glossary_index[j]] = content[j];\n",
    "                player_career_split.append([ID, name, season, team, situations[tag_num]] + content_dest);\n",
    "            elif tag_num >= 0:\n",
    "                content = status[situations_len[tag_num]:].replace('i', ' ').split();\n",
    "                content_dest = [np.nan] * (len(columns_career) - 5);\n",
    "                for j in range(len(glossary)):\n",
    "                    content_dest[glossary_index[j]] = content[j];\n",
    "                player_career_split.append([ID, name, season, team, situations[tag_num]] + content_dest);\n",
    "    \n",
    "    print([len(x) for x in player_career_split]);\n",
    "    return player_career_split;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6728ca",
   "metadata": {},
   "source": [
    "## Scraping the split pages and extend the dataframe.\n",
    "Now this is where the scraping happens. Let's keep our fingers crossed and hope that we won't get blocked :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player_season_split = pd.DataFrame(columns = columns_career);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(df_player_season_stats.shape[0]): # Ideally we want to do this, but need to debug once in a while.\n",
    "for i in range(43521,df_player_season_stats.shape[0]): # Break into pieces\n",
    "#for i in range(20):\n",
    "    psp = scrape_player_season_split(i);\n",
    "    if psp != -1:\n",
    "        df_player_season_split = df_player_season_split.append(pd.DataFrame(psp[0:], columns = columns_career));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6,24):\n",
    "    df_player_season_split[columns_career[i]] = df_player_season_split[columns_career[i]].str.replace('i','').astype(float); #apply(lambda x: int(x) if isinstance(x, str) else x)\n",
    "\n",
    "for i in range(24,27):\n",
    "    df_player_season_split[columns_career[i]] = df_player_season_split[columns_career[i]].str.replace('-','');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player_season_split.to_csv(\"player_season_split_data.csv\")\n",
    "print(df_player_season_split.shape) # (413971, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca537bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_player_season_split.iloc[90:100]\n",
    "df_player_yearly_stats.iloc[43519:43525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7b021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3];\n",
    "b = [];\n",
    "c = None;\n",
    "#a.append(c)\n",
    "#a.extend(c)\n",
    "a != max\n",
    "\n",
    "# list(range(10)) #0-9\n",
    "#list(range(10,20)) #10-19\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_player_season_split.iloc[80:90]\n",
    "print(i)\n",
    "df_player_season_split.shape\n",
    "[len(x) for x in psp]\n",
    "psp[-1]\n",
    "\"si djo201iwd\".replace('i', ' ').split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
